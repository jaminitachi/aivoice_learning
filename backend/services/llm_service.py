import os
from openai import AsyncOpenAI

# --- í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ---
# .env íŒŒì¼ì—ì„œ LLM ê´€ë ¨ ì„¤ì •ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.
OPENROUTER_API_KEY = os.getenv("LLM_API_KEY")
BASE_URL = os.getenv("LLM_BASE_URL", "https://openrouter.ai/api/v1")
MODEL_NAME = os.getenv("LLM_MODEL_NAME", "x-ai/grok-4-fast")


if not OPENROUTER_API_KEY:
    raise ValueError("LLM_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (OpenRouter API Key)")

# --- OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
# OpenRouter APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ base_urlì„ ì§€ì •í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
client = AsyncOpenAI(
    base_url=BASE_URL,
    api_key=OPENROUTER_API_KEY,
)

def get_grok_client() -> AsyncOpenAI:
    """
    Grok LLM í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜
    í”¼ë“œë°± ì„œë¹„ìŠ¤ ë“± ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í´ë¼ì´ì–¸íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    """
    return client

async def refine_stt_text(raw_stt_text: str) -> str:
    """
    STT ê²°ê³¼ë¥¼ ì •ì œí•©ë‹ˆë‹¤.
    - ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±° (ìŒí–¥ íš¨ê³¼, ë°°ê²½ìŒ ë“±)
    - ë°˜ë³µëœ ë‹¨ì–´/êµ¬ë¬¸ ì •ë¦¬
    - ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    - ê°„ë‹¨í•œ ë¬¸ë²• ë³´ì • (ëŒ€ì†Œë¬¸ì ë“±)
    
    Args:
        raw_stt_text: STT ì›ë³¸ í…ìŠ¤íŠ¸
    
    Returns:
        ì •ì œëœ í…ìŠ¤íŠ¸
    """
    import re
    
    # 1. ê¸°ë³¸ ì •ì œ (ë¹ ë¥¸ ê·œì¹™ ê¸°ë°˜)
    text = raw_stt_text.strip()
    
    # ê´„í˜¸ ì•ˆ ë‚´ìš© ì œê±° (ì˜ˆ: "[ìŒì•…]", "(ë°°ê²½ìŒ)", "[ì›ƒìŒ]" ë“±)
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\(.*?\)', '', text)
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    text = re.sub(r'\s+', ' ', text)
    text = text.strip()
    
    # 2. LLMì„ ì‚¬ìš©í•œ ê³ ê¸‰ ì •ì œ (ë°˜ë³µ ì œê±°, ë¬¸ë§¥ìƒ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì •ë¦¬)
    try:
        refine_prompt = f"""Clean up this speech-to-text transcription. Remove:
- Repeated words or phrases (e.g., "I I think" â†’ "I think")
- Filler words that don't add meaning (um, uh, like) ONLY if excessive
- Any remaining transcription artifacts

Keep the natural conversational tone. Don't change the meaning.

Original: "{text}"

Return ONLY the cleaned text, nothing else."""

        response = await client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "system",
                    "content": "You are a text cleanup assistant. Return only the cleaned text, no explanations."
                },
                {
                    "role": "user",
                    "content": refine_prompt
                }
            ],
            max_tokens=300,
            temperature=0.3  # ë‚®ì€ ì˜¨ë„ë¡œ ì¼ê´€ì„± ìœ ì§€
        )
        
        refined = response.choices[0].message.content.strip()
        
        # ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§„ ê²½ìš° ì œê±°
        if refined.startswith('"') and refined.endswith('"'):
            refined = refined[1:-1]
        
        print(f"ğŸ”§ STT Refined: '{raw_stt_text}' â†’ '{refined}'")
        return refined if refined else text
        
    except Exception as e:
        print(f"âš ï¸ STT ì •ì œ ì¤‘ ì˜¤ë¥˜ (ì›ë³¸ ë°˜í™˜): {e}")
        return text

async def generate_suggested_responses(
    conversation_history: list,
    character_name: str,
    difficulty: str
) -> list:
    """
    ëŒ€í™” ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” 3ê°€ì§€ ì¶”ì²œ ë©˜íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    
    Args:
        conversation_history: í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” íˆìŠ¤í† ë¦¬
        character_name: ëŒ€í™” ìƒëŒ€ ìºë¦­í„° ì´ë¦„
        difficulty: ë‚œì´ë„ (beginner, intermediate, advanced)
    
    Returns:
        3ê°œì˜ ì¶”ì²œ ë©˜íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    try:
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        history_text = ""
        for msg in conversation_history[-6:]:  # ìµœê·¼ 6ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
            speaker = "You" if msg["speaker"] == "user" else character_name
            history_text += f"{speaker}: {msg['text']}\n"
        
        # ë‚œì´ë„ë³„ ì§€ì‹œì‚¬í•­
        difficulty_instructions = {
            "beginner": "Use VERY simple words that 10-year-old children understand. NO idioms, NO phrasal verbs.",
            "intermediate": "Use high school level vocabulary. Clear and straightforward language.",
            "advanced": "Use natural, fluent English with college-level vocabulary."
        }
        
        vocab_instruction = difficulty_instructions.get(difficulty, difficulty_instructions["intermediate"])
        
        prompt = f"""Based on this conversation, suggest 3 short, natural responses the user could say next.

Conversation so far:
{history_text}

Requirements:
- Each response should be 5-10 words maximum
- Make them natural and conversational
- Vary the responses (question, statement, follow-up)
- {vocab_instruction}
- Return ONLY a JSON array of 3 strings, nothing else

Example format: ["Response 1", "Response 2", "Response 3"]"""

        response = await client.chat.completions.create(
            model=MODEL_NAME,
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful assistant that generates natural conversation suggestions. Return only valid JSON."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=150,
            temperature=0.8
        )
        
        suggestions_text = response.choices[0].message.content.strip()
        
        # JSON íŒŒì‹±
        import json
        import re
        
        # JSON ë°°ì—´ë§Œ ì¶”ì¶œ (í˜¹ì‹œ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆì„ ê²½ìš°)
        json_match = re.search(r'\[.*\]', suggestions_text, re.DOTALL)
        if json_match:
            suggestions = json.loads(json_match.group())
        else:
            suggestions = json.loads(suggestions_text)
        
        # 3ê°œê°€ ì•„ë‹ˆë©´ ì¡°ì •
        if len(suggestions) < 3:
            suggestions.extend(["Tell me more", "That's interesting", "What about you?"][:3-len(suggestions)])
        
        return suggestions[:3]
        
    except Exception as e:
        print(f"âš ï¸ ì¶”ì²œ ë©˜íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        # ê¸°ë³¸ ì¶”ì²œ ë©˜íŠ¸ ë°˜í™˜
        default_suggestions = {
            "beginner": ["I like that!", "Tell me more.", "What about you?"],
            "intermediate": ["That's interesting.", "I see what you mean.", "How do you feel about it?"],
            "advanced": ["That's a great point.", "I hadn't thought of it that way.", "What's your take on this?"]
        }
        return default_suggestions.get(difficulty, default_suggestions["intermediate"])


async def get_llm_response(user_text: str, system_prompt: str, conversation_history: list = None) -> str:
    """
    OpenRouterë¥¼ í†µí•´ gpt-5-chat ëª¨ë¸ì„ í˜¸ì¶œí•˜ì—¬ AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ í•¨ê»˜ ì „ë‹¬í•˜ì—¬ ë§¥ë½ì„ ìœ ì§€í•©ë‹ˆë‹¤.
    
    Args:
        user_text: í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€
        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìºë¦­í„° ì„¤ì •)
        conversation_history: ì´ì „ ëŒ€í™” íˆìŠ¤í† ë¦¬ [{"speaker": "user", "text": "..."}, ...]
    
    Returns:
        AI ì‘ë‹µ í…ìŠ¤íŠ¸
    """
    try:
        # ë©”ì‹œì§€ ë°°ì—´ êµ¬ì„±
        messages = [{"role": "system", "content": system_prompt}]
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ì¶”ê°€ (ë§¥ë½ ìœ ì§€)
        if conversation_history:
            for msg in conversation_history:
                role = "user" if msg["speaker"] == "user" else "assistant"
                messages.append({"role": role, "content": msg["text"]})
        
        # í˜„ì¬ ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        messages.append({"role": "user", "content": user_text})
        
        print(f"\n{'ğŸ¤–'*30}")
        print(f"[LLM ì „ì²´ ë©”ì‹œì§€ í™•ì¸]")
        print(f"  ëª¨ë¸: {MODEL_NAME}")
        print(f"  ì´ ë©”ì‹œì§€ ìˆ˜: {len(messages)}ê°œ")
        for i, msg in enumerate(messages, 1):
            content_preview = msg['content'][:80] + "..." if len(msg['content']) > 80 else msg['content']
            print(f"  {i}. [{msg['role'].upper()}]: {content_preview}")
        print(f"{'ğŸ¤–'*30}\n")
        
        completion = await client.chat.completions.create(
            model=MODEL_NAME,
            messages=messages,
            max_tokens=100,
            temperature=0.7,
            extra_body={
                "reasoning": {
                    "enabled": True
                }
            }
        )
        ai_message = completion.choices[0].message.content
        return ai_message.strip() if ai_message else ""
    
    except Exception as e:
        # openai ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ë°œìƒí•˜ëŠ” ëª¨ë“  ì˜ˆì™¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        print(f"OpenRouter API í˜¸ì¶œ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        # í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ë‹¬ë  ìµœì¢… ì˜ˆì™¸ ë©”ì‹œì§€ë¥¼ ì¼ê´€ë˜ê²Œ ê´€ë¦¬í•©ë‹ˆë‹¤.
        raise Exception("AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
