"use client";

import { useState, useRef, useEffect } from "react";
import { Mic, StopCircle, User, ChevronLeft } from "lucide-react";
import Link from "next/link";
import Image from "next/image";
import { API_ENDPOINTS, WS_ENDPOINTS } from "@/utils/config";
import router from "next/router";

// --- Fingerprint ìƒì„± í•¨ìˆ˜ ---
async function generateFingerprint(): Promise<string> {
  try {
    // Canvas Fingerprinting
    const canvas = document.createElement("canvas");
    const ctx = canvas.getContext("2d");
    if (ctx) {
      ctx.textBaseline = "top";
      ctx.font = "14px Arial";
      ctx.fillStyle = "#f60";
      ctx.fillRect(125, 1, 62, 20);
      ctx.fillStyle = "#069";
      ctx.fillText("Browser Fingerprint", 2, 15);
      ctx.fillStyle = "rgba(102, 204, 0, 0.7)";
      ctx.fillText("Canvas Fingerprint", 4, 17);
    }
    const canvasData = canvas.toDataURL();

    // ë¸Œë¼ìš°ì € í™˜ê²½ ì •ë³´ ìˆ˜ì§‘
    const fingerprint = {
      canvas: canvasData,
      userAgent: navigator.userAgent,
      language: navigator.language,
      platform: navigator.platform,
      screenResolution: `${screen.width}x${screen.height}`,
      screenColorDepth: screen.colorDepth,
      timezone: Intl.DateTimeFormat().resolvedOptions().timeZone,
      deviceMemory: (navigator as any).deviceMemory || 0,
      hardwareConcurrency: navigator.hardwareConcurrency || 0,
    };

    // JSON ë¬¸ìì—´ë¡œ ë³€í™˜
    const fingerprintString = JSON.stringify(fingerprint);

    // SHA-256 í•´ì‹œ ìƒì„±
    const encoder = new TextEncoder();
    const data = encoder.encode(fingerprintString);
    const hashBuffer = await crypto.subtle.digest("SHA-256", data);
    const hashArray = Array.from(new Uint8Array(hashBuffer));
    const hashHex = hashArray
      .map((b) => b.toString(16).padStart(2, "0"))
      .join("");

    console.log("ğŸ” Fingerprint ìƒì„±:", hashHex.substring(0, 16) + "...");
    return hashHex;
  } catch (error) {
    console.error("Fingerprint ìƒì„± ì˜¤ë¥˜:", error);
    // ì˜¤ë¥˜ ì‹œ ëœë¤ ID ë°˜í™˜ (fallback)
    return "fallback-" + Math.random().toString(36).substring(2, 15);
  }
}

// --- íƒ€ì… ì •ì˜ ---
interface Message {
  speaker: "user" | "ai";
  text: string;
  imageUrl?: string;
}

interface Character {
  id: string;
  name: string;
  imageUrl: string;
  init_message: string;
}

interface ChatPageProps {
  params: {
    characterId: string;
  };
}

// --- WebSocket ë©”ì‹œì§€ íƒ€ì… ---
interface WebSocketMessage {
  type: string;
  [key: string]: any;
}

// --- ë©”ì¸ ì»´í¬ë„ŒíŠ¸ ---
export default function ConversationWebSocketPage({ params }: ChatPageProps) {
  const { characterId } = params;

  // --- ìƒíƒœ ê´€ë¦¬ ---
  const [character, setCharacter] = useState<Character | null>(null);
  const [messages, setMessages] = useState<Message[]>([]);
  const [isRecording, setIsRecording] = useState(false);
  const [isLoading, setIsLoading] = useState(false);
  const [connectionStatus, setConnectionStatus] = useState<
    "disconnected" | "connecting" | "connected"
  >("disconnected");
  const [statusMessage, setStatusMessage] = useState("");
  const [turnCount, setTurnCount] = useState(0);
  const [maxTurns, setMaxTurns] = useState(10);
  const [sessionId, setSessionId] = useState<string | null>(null);
  const [isSessionCompleted, setIsSessionCompleted] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);
  const messagesEndRef = useRef<HTMLDivElement>(null);
  const wsRef = useRef<WebSocket | null>(null);

  // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨
  const audioContextRef = useRef<AudioContext | null>(null);
  const audioBuffersRef = useRef<ArrayBuffer[]>([]);
  const isPlayingRef = useRef(false);

  // Init ì˜¤ë””ì˜¤ ì „ìš© ë²„í¼
  const initAudioBuffersRef = useRef<ArrayBuffer[]>([]);
  const isPlayingInitRef = useRef(false);

  // ë©”ì‹œì§€ ìë™ ìŠ¤í¬ë¡¤
  useEffect(() => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  }, [messages, isLoading]);

  // ìºë¦­í„° ì •ë³´ ë¡œë“œ
  useEffect(() => {
    const fetchCharacterInfo = async () => {
      try {
        const response = await fetch(API_ENDPOINTS.CHARACTERS);
        const characters: Character[] = await response.json();
        const currentChar = characters.find((c) => c.id === characterId);
        setCharacter(currentChar || null);
      } catch (error) {
        console.error("Failed to fetch character info:", error);
      }
    };
    fetchCharacterInfo();
  }, [characterId]);

  // WebSocket ì—°ê²° ì„¤ì •
  useEffect(() => {
    if (!character) return;

    // WebSocket ì—°ê²°
    const connectWebSocket = async () => {
      setConnectionStatus("connecting");
      const ws = new WebSocket(WS_ENDPOINTS.CHAT(characterId));

      ws.onopen = async () => {
        console.log("WebSocket connected");
        setConnectionStatus("connected");

        // âœ… Fingerprint ìƒì„± ë° ì „ì†¡
        const fingerprint = await generateFingerprint();
        ws.send(
          JSON.stringify({
            type: "init",
            fingerprint: fingerprint,
          })
        );
        console.log("ğŸ“¤ Fingerprint ì „ì†¡ ì™„ë£Œ");
      };

      ws.onmessage = async (event) => {
        const data: WebSocketMessage = JSON.parse(event.data);
        handleWebSocketMessage(data);
      };

      ws.onerror = (error) => {
        console.error("WebSocket error:", error);
        setConnectionStatus("disconnected");
      };

      ws.onclose = () => {
        console.log("WebSocket disconnected");
        setConnectionStatus("disconnected");
        // ìë™ ì¬ì—°ê²° (5ì´ˆ í›„)
        setTimeout(() => {
          if (wsRef.current?.readyState !== WebSocket.OPEN) {
            connectWebSocket();
          }
        }, 5000);
      };

      wsRef.current = ws;
    };

    connectWebSocket();

    // í´ë¦°ì—…
    return () => {
      if (wsRef.current) {
        wsRef.current.close();
        wsRef.current = null;
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
    };
  }, [character, characterId]);

  // WebSocket ë©”ì‹œì§€ ì²˜ë¦¬
  const handleWebSocketMessage = async (data: WebSocketMessage) => {
    switch (data.type) {
      case "connected":
        console.log("Connected to character:", data.character_name);
        setSessionId(data.session_id);
        setMaxTurns(data.max_turns || 10);

        // ìºë¦­í„°ì˜ ì´ˆê¸° ë©”ì‹œì§€ í‘œì‹œ
        if (data.init_message) {
          setMessages([
            {
              speaker: "ai",
              text: data.init_message,
              imageUrl: character?.imageUrl,
            },
          ]);
        }
        break;

      case "init_audio_stream_start":
        // ì´ˆê¸° ë©”ì‹œì§€ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
        console.log("ğŸµ Init ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘");
        initAudioBuffersRef.current = [];
        isPlayingInitRef.current = false;
        if (!audioContextRef.current) {
          audioContextRef.current = new AudioContext();
        }
        break;

      case "init_audio_chunk":
        // ì´ˆê¸° ë©”ì‹œì§€ ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  ë° ì¬ìƒ
        const initChunkData = atob(data.data);
        const initChunkArray = new Uint8Array(initChunkData.length);
        for (let i = 0; i < initChunkData.length; i++) {
          initChunkArray[i] = initChunkData.charCodeAt(i);
        }
        initAudioBuffersRef.current.push(initChunkArray.buffer);
        console.log(
          `ğŸµ Init ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  (${initAudioBuffersRef.current.length}ê°œ)`
        );

        // ì²« ì²­í¬ë¶€í„° ì¦‰ì‹œ ì¬ìƒ ì‹œì‘
        if (
          !isPlayingInitRef.current &&
          initAudioBuffersRef.current.length > 0
        ) {
          playInitAudioStream();
        }
        break;

      case "init_audio_stream_end":
        // ì´ˆê¸° ë©”ì‹œì§€ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ
        console.log("âœ… ì´ˆê¸° ë©”ì‹œì§€ ìŒì„± ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ");
        break;

      case "status":
        setStatusMessage(data.message);
        break;

      case "turn_count_update":
        setTurnCount(data.turn_count);
        break;

      case "session_completed":
        setIsSessionCompleted(true);
        setSessionId(data.session_id);
        // ë¡œë”©ì€ audio_stream_endì—ì„œ ìë™ìœ¼ë¡œ êº¼ì§
        // í”¼ë“œë°± í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
        setTimeout(() => {
          window.location.href = `/feedback/${data.session_id}`;
        }, 2000);
        break;

      case "stt_result":
        // ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        setMessages((prev) => [...prev, { speaker: "user", text: data.text }]);
        break;

      case "llm_result":
        // AI ë©”ì‹œì§€ ì¶”ê°€
        setMessages((prev) => [...prev, { speaker: "ai", text: data.text }]);
        break;

      case "character_image":
        // ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ì— ì´ë¯¸ì§€ ì¶”ê°€
        setMessages((prev) => {
          const updated = [...prev];
          for (let i = updated.length - 1; i >= 0; i--) {
            if (updated[i].speaker === "ai") {
              updated[i].imageUrl = data.image_url;
              break;
            }
          }
          return updated;
        });
        break;

      case "audio_stream_start":
        // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
        audioBuffersRef.current = [];
        if (!audioContextRef.current) {
          audioContextRef.current = new AudioContext();
        }
        break;

      case "audio_chunk":
        // ì˜¤ë””ì˜¤ ì²­í¬ ìˆ˜ì‹  ë° ì¬ìƒ
        const chunkData = atob(data.data); // base64 ë””ì½”ë”©
        const chunkArray = new Uint8Array(chunkData.length);
        for (let i = 0; i < chunkData.length; i++) {
          chunkArray[i] = chunkData.charCodeAt(i);
        }
        audioBuffersRef.current.push(chunkArray.buffer);

        // ì²« ì²­í¬ë¶€í„° ì¦‰ì‹œ ì¬ìƒ ì‹œì‘
        if (!isPlayingRef.current && audioBuffersRef.current.length > 0) {
          playAudioStream();
        }
        break;

      case "audio_stream_end":
        setIsLoading(false);
        setStatusMessage("");
        break;

      case "blocked":
        // ì°¨ë‹¨ëœ ê²½ìš° - ê¹¨ë—í•œ ì•Œë¦¼ì°½ê³¼ í™ˆìœ¼ë¡œ ì´ë™
        console.warn("ğŸš« ì‚¬ìš©ì ì°¨ë‹¨:", data.message);
        setStatusMessage("");
        setIsLoading(false);
        alert(data.message);
        router.push("/");
        break;

      case "error":
        console.error("WebSocket error:", data.message);
        setStatusMessage("");
        setIsLoading(false);
        alert(data.message);
        break;

      default:
        console.log("Unknown message type:", data.type);
    }
  };

  // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¬ìƒ (ì¼ë°˜ ë©”ì‹œì§€ìš©)
  const playAudioStream = async () => {
    if (!audioContextRef.current || audioBuffersRef.current.length === 0)
      return;

    isPlayingRef.current = true;

    try {
      // ëª¨ë“  ì²­í¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
      const totalLength = audioBuffersRef.current.reduce(
        (acc, arr) => acc + arr.byteLength,
        0
      );
      const combined = new Uint8Array(totalLength);
      let offset = 0;

      for (const buffer of audioBuffersRef.current) {
        combined.set(new Uint8Array(buffer), offset);
        offset += buffer.byteLength;
      }

      // AudioContextë¡œ ë””ì½”ë”© ë° ì¬ìƒ
      const audioBuffer = await audioContextRef.current.decodeAudioData(
        combined.buffer
      );
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);

      source.onended = () => {
        isPlayingRef.current = false;
      };

      source.start(0);
    } catch (error) {
      console.error("ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:", error);
      isPlayingRef.current = false;
    }
  };

  // Init ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì¬ìƒ (ì´ˆê¸° ë©”ì‹œì§€ìš©)
  const playInitAudioStream = async () => {
    if (!audioContextRef.current || initAudioBuffersRef.current.length === 0) {
      console.log("âš ï¸ Init ì˜¤ë””ì˜¤ ì¬ìƒ ë¶ˆê°€: AudioContext ë˜ëŠ” ë²„í¼ ì—†ìŒ");
      return;
    }

    isPlayingInitRef.current = true;
    console.log(
      `ğŸµ Init ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ (ì²­í¬ ${initAudioBuffersRef.current.length}ê°œ)`
    );

    try {
      // ëª¨ë“  ì²­í¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
      const totalLength = initAudioBuffersRef.current.reduce(
        (acc, arr) => acc + arr.byteLength,
        0
      );
      const combined = new Uint8Array(totalLength);
      let offset = 0;

      for (const buffer of initAudioBuffersRef.current) {
        combined.set(new Uint8Array(buffer), offset);
        offset += buffer.byteLength;
      }

      console.log(`ğŸµ Init ì˜¤ë””ì˜¤ ë””ì½”ë”© ì¤‘ (${totalLength} bytes)...`);

      // AudioContextë¡œ ë””ì½”ë”© ë° ì¬ìƒ
      const audioBuffer = await audioContextRef.current.decodeAudioData(
        combined.buffer
      );
      const source = audioContextRef.current.createBufferSource();
      source.buffer = audioBuffer;
      source.connect(audioContextRef.current.destination);

      source.onended = () => {
        isPlayingInitRef.current = false;
        console.log("âœ… Init ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ");
      };

      source.start(0);
      console.log("ğŸµ Init ì˜¤ë””ì˜¤ ì¬ìƒ ì¤‘...");
    } catch (error) {
      console.error("âŒ Init ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:", error);
      isPlayingInitRef.current = false;
    }
  };

  // ë…¹ìŒ ì‹œì‘
  const startRecording = async () => {
    if (connectionStatus !== "connected") {
      alert("WebSocketì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.");
      return;
    }

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: "audio/webm;codecs=opus",
      });
      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = async () => {
        const audioBlob = new Blob(audioChunksRef.current, {
          type: "audio/webm",
        });
        await sendAudioToWebSocket(audioBlob);

        // ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
        if (streamRef.current) {
          streamRef.current.getTracks().forEach((track) => track.stop());
          streamRef.current = null;
        }
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error("ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:", error);
      alert("ë§ˆì´í¬ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
    }
  };

  // ë…¹ìŒ ì¤‘ì§€
  const stopRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  };

  // WebSocketìœ¼ë¡œ ì˜¤ë””ì˜¤ ì „ì†¡
  const sendAudioToWebSocket = async (audioBlob: Blob) => {
    if (!wsRef.current || wsRef.current.readyState !== WebSocket.OPEN) {
      alert("WebSocketì´ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
      return;
    }

    setIsLoading(true);

    try {
      // Blobì„ Base64ë¡œ ë³€í™˜
      const reader = new FileReader();
      reader.readAsDataURL(audioBlob);
      reader.onloadend = () => {
        const base64Audio = reader.result as string;
        // "data:audio/webm;base64," ì œê±°
        const base64Data = base64Audio.split(",")[1];

        // WebSocketìœ¼ë¡œ ì „ì†¡
        wsRef.current?.send(
          JSON.stringify({
            type: "audio",
            audio: base64Data,
          })
        );
      };
    } catch (error) {
      console.error("ì˜¤ë””ì˜¤ ì „ì†¡ ì‹¤íŒ¨:", error);
      setIsLoading(false);
    }
  };

  if (!character) {
    return (
      <div className="min-h-screen flex items-center justify-center bg-gradient-to-b from-blue-50 to-white">
        <p className="text-gray-600">ìºë¦­í„° ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...</p>
      </div>
    );
  }

  return (
    <div className="min-h-screen bg-gradient-to-b from-blue-50 to-white flex flex-col">
      {/* í—¤ë” */}
      <header className="bg-white shadow-sm border-b border-gray-200 px-6 py-4">
        <div className="flex items-center justify-between">
          <Link
            href="/"
            className="flex items-center gap-2 text-gray-600 hover:text-gray-900 transition-colors"
          >
            <ChevronLeft className="w-5 h-5" />
            <span className="font-medium">ëŒì•„ê°€ê¸°</span>
          </Link>
          <h1 className="text-xl font-bold text-gray-900">
            {character.name}ì™€ì˜ ëŒ€í™”
          </h1>
          <div
            className={`px-3 py-1 rounded-full text-sm font-medium ${
              connectionStatus === "connected"
                ? "bg-green-100 text-green-700"
                : connectionStatus === "connecting"
                ? "bg-yellow-100 text-yellow-700"
                : "bg-red-100 text-red-700"
            }`}
          >
            {connectionStatus === "connected"
              ? "ì—°ê²°ë¨"
              : connectionStatus === "connecting"
              ? "ì—°ê²° ì¤‘..."
              : "ì—°ê²° ëŠê¹€"}
          </div>
        </div>

        {/* í„´ ì¹´ìš´í„° */}
        <div className="mt-3 flex items-center justify-center gap-4">
          <div className="flex items-center gap-2">
            <div className="text-sm text-gray-600">ëŒ€í™” ì§„í–‰:</div>
            <div className="flex items-center gap-1">
              {Array.from({ length: maxTurns }).map((_, idx) => (
                <div
                  key={idx}
                  className={`w-3 h-3 rounded-full ${
                    idx < turnCount ? "bg-blue-500" : "bg-gray-300"
                  }`}
                  title={`${idx + 1}í„´`}
                />
              ))}
            </div>
            <div className="text-sm font-semibold text-gray-900">
              {turnCount}/{maxTurns}
            </div>
          </div>
        </div>
      </header>

      {/* ëŒ€í™” ì˜ì—­ */}
      <div className="flex-1 overflow-y-auto px-6 py-8 space-y-6">
        {/* ì„¸ì…˜ ì™„ë£Œ ë©”ì‹œì§€ */}
        {isSessionCompleted && (
          <div className="bg-green-50 border-2 border-green-500 rounded-xl p-6 text-center mb-6 animate-pulse">
            <h2 className="text-xl font-bold text-green-800 mb-2">
              ğŸ‰ ëŒ€í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!
            </h2>
            <p className="text-green-700 mb-4">
              ì ì‹œ í›„ í”¼ë“œë°± í˜ì´ì§€ë¡œ ì´ë™í•©ë‹ˆë‹¤...
            </p>
            <div className="flex items-center justify-center gap-2">
              <div className="w-2 h-2 bg-green-600 rounded-full animate-bounce"></div>
              <div className="w-2 h-2 bg-green-600 rounded-full animate-bounce delay-75"></div>
              <div className="w-2 h-2 bg-green-600 rounded-full animate-bounce delay-150"></div>
            </div>
          </div>
        )}

        {messages.length === 0 && !isLoading && !isSessionCompleted && (
          <div className="text-center text-gray-500 mt-12">
            <p className="text-lg">ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”</p>
            <p className="text-sm mt-2">
              10ë²ˆì˜ ëŒ€í™” í›„ í”¼ë“œë°±ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤
            </p>
          </div>
        )}

        {messages.map((msg, idx) => (
          <div
            key={idx}
            className={`flex gap-4 ${
              msg.speaker === "user" ? "justify-end" : "justify-start"
            }`}
          >
            {msg.speaker === "ai" && (
              <div className="flex-shrink-0">
                {msg.imageUrl ? (
                  <Image
                    src={msg.imageUrl}
                    alt={character.name}
                    width={48}
                    height={48}
                    className="rounded-full object-cover"
                  />
                ) : (
                  <div className="w-12 h-12 rounded-full bg-gradient-to-br from-purple-400 to-pink-400 flex items-center justify-center text-white font-semibold">
                    AI
                  </div>
                )}
              </div>
            )}

            <div
              className={`max-w-md px-4 py-3 rounded-2xl shadow-sm ${
                msg.speaker === "user"
                  ? "bg-blue-500 text-white"
                  : "bg-white text-gray-800 border border-gray-200"
              }`}
            >
              <p className="text-sm leading-relaxed whitespace-pre-wrap">
                {msg.text}
              </p>
            </div>

            {msg.speaker === "user" && (
              <div className="flex-shrink-0">
                <div className="w-12 h-12 rounded-full bg-gradient-to-br from-blue-400 to-indigo-500 flex items-center justify-center">
                  <User className="w-6 h-6 text-white" />
                </div>
              </div>
            )}
          </div>
        ))}

        {isLoading && (
          <div className="flex gap-4 justify-start">
            <div className="flex-shrink-0">
              <div className="w-12 h-12 rounded-full bg-gradient-to-br from-purple-400 to-pink-400 flex items-center justify-center text-white font-semibold">
                AI
              </div>
            </div>
            <div className="max-w-md px-4 py-3 rounded-2xl bg-white border border-gray-200 shadow-sm">
              <div className="flex items-center gap-2">
                <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce"></div>
                <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce delay-75"></div>
                <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce delay-150"></div>
                {statusMessage && (
                  <p className="ml-2 text-sm text-gray-600">{statusMessage}</p>
                )}
              </div>
            </div>
          </div>
        )}

        <div ref={messagesEndRef} />
      </div>

      {/* ë…¹ìŒ ë²„íŠ¼ */}
      <div className="bg-white border-t border-gray-200 px-6 py-6">
        <div className="max-w-2xl mx-auto flex justify-center">
          <button
            onClick={isRecording ? stopRecording : startRecording}
            disabled={
              isLoading ||
              connectionStatus !== "connected" ||
              isSessionCompleted
            }
            className={`group relative w-20 h-20 rounded-full flex items-center justify-center transition-all transform hover:scale-105 active:scale-95 disabled:opacity-50 disabled:cursor-not-allowed ${
              isRecording
                ? "bg-red-500 shadow-lg shadow-red-500/50"
                : "bg-gradient-to-br from-blue-500 to-indigo-600 shadow-lg shadow-blue-500/50"
            }`}
          >
            {isRecording ? (
              <StopCircle className="w-10 h-10 text-white" />
            ) : (
              <Mic className="w-10 h-10 text-white" />
            )}

            {isRecording && (
              <span className="absolute -top-2 -right-2 w-4 h-4 bg-red-500 rounded-full animate-ping"></span>
            )}
          </button>
        </div>
        <p className="text-center text-sm text-gray-500 mt-4">
          {isSessionCompleted
            ? "ëŒ€í™”ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤"
            : isRecording
            ? "ë…¹ìŒ ì¤‘... ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ì „ì†¡í•˜ì„¸ìš”"
            : connectionStatus === "connected"
            ? "ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë§í•˜ê¸°"
            : "WebSocket ì—°ê²° ëŒ€ê¸° ì¤‘..."}
        </p>
      </div>
    </div>
  );
}
